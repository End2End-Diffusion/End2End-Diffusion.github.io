<!doctype html>
<html lang="en">
    <head>
        <title>REPA-E: Unlocking VAE for End-to-End Tuning of Latent Diffusion Transformers</title>
        <link rel="icon" type="image/png" href="../static/img/kitty.png">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Open Graph -->
        <meta property="og:url" content="https://end2end-diffusion.github.io/repa-e" />
        <meta property="og:title" content="REPA-E: Unlocking VAE for End-to-End Tuning of Latent Diffusion Transformers" />
        <meta property="og:description" content="REPA-E enables stable and effective joint training of both the VAE and the diffusion model, achieving state-of-the-art FID scores of 1.12 and 1.69 on ImageNet 256×256." />

        <!-- Twitter -->
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:title" content="REPA-E: Unlocking VAE for End-to-End Tuning of Latent Diffusion Transformers" />
        <meta name="twitter:description" content="REPA-E enables stable and effective joint training of both the VAE and the diffusion model, achieving state-of-the-art FID scores of 1.12 and 1.69 on ImageNet 256×256." />

        <script src="./static/js/distill_template.v2.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

        <script defer="" src="./static/js/hider.js"></script>

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500&display=swap" rel="stylesheet">

        <link rel="stylesheet" href="../static/css/paper-layout.css">
        <link rel="stylesheet" href="./static/css/style.css">
        <link rel="stylesheet" href="./static/css/custom.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>

        <!-- Prism for syntax highlighting -->
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

        <!-- medium zoom -->
        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>
        <script defer src="./static/js/medium-zoom.min.js"></script>
        <script defer src="./static/js/zoom.js"></script>
        <script defer src="./static/js/tabs.js"></script>

        <!-- Quickstart styling -->
        <style>
        .quickstart-box {
            background: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 30px;
            margin: 20px 0;
        }
        .tab-container {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 20px 0;
            border-bottom: 2px solid #ddd;
            padding-bottom: 10px;
        }
        .tab-button {
            padding: 10px 20px;
            background: #f0f0f0;
            border: none;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.3s;
            border-radius: 5px 5px 0 0;
        }
        .tab-button:hover {
            background: #e0e0e0;
        }
        .tab-button.active {
            background: #2563eb;
            color: white;
        }
        .tab-content {
            display: none;
            padding: 20px 0;
        }
        .tab-content.active {
            display: block;
        }
        .install-note {
            background: #ffffff;
            border-left: 4px solid #2563eb;
            padding: 15px;
            margin: 20px 0;
        }
        .install-note strong {
            font-weight: 600;
        }
        .quickstart-example {
            margin: 30px 0;
        }
        .quickstart-example h3 {
            color: #2563eb;
            margin-bottom: 10px;
        }
        .quickstart-example pre {
            background-color: #f5f5f5;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            overflow-x: auto;
        }
        /* News section styling */
        .news-section {
            margin: 2em 0;
            padding: 1em 0;
        }
        .news-item {
            margin: 16px 0;
        }
        .news-item .material-icons {
            vertical-align: -6px;
            color: #2563eb;
        }
        </style>
        <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    </head>
    <body>

        <!-- Sticky Table of Contents -->
        <nav class="toc-container">
            <h4>Contents</h4>
            <ul>
                <li><a href="#quickstart">Quickstart</a></li>
                <li><a href="#overview">Overview</a></li>
                <li><a href="#accelerated-performance">E2E Leads to Faster Training</a></li>
                <li><a href="#improved-latent-space">E2E Leads to Improved Latent Space</a></li>
                <li><a href="#drop-in-replacements">E2E VAEs are Better than Regular VAEs</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
            </ul>
        </nav>

        <nav style="background-color: #fff; border-bottom: 1px solid #e5e5e5; padding: 12px 0;">
            <div style="max-width: 1200px; margin: 0 auto; padding: 0 20px; display: flex; justify-content: space-between; align-items: center;">
                <a href="../index.html" style="color: #1a1a1a; text-decoration: none; font-size: 15px; font-weight: 500;">
                    <i class="fas fa-arrow-left" style="margin-right: 8px; opacity: 0.5;"></i>
                    End2End Diffusion
                </a>
                <div style="display: flex; gap: 20px;">
                    <a href="../repa-e-t2i/" style="color: #666; text-decoration: none; font-size: 14px;">REPA-E-T2I</a>
                    <a href="../irepa/" style="color: #666; text-decoration: none; font-size: 14px;">iREPA</a>
                </div>
            </div>
        </nav>

        <div class="header-wrapper">
            <div class="header-container" id="header-container">
                <div class="header-content">
                    <h1 style="margin-top: 0px">REPA-E: Unlocking VAE for</h1>
                    <h2>End-to-End Tuning of <em>Latent Diffusion Transformers</em></h2>

                    <p>
                        We show that latent diffusion models and their VAE tokenizer can be effectively trained end-to-end using a simple representation-alignment (REPA) loss.
                        REPA-E achieves state-of-the-art FID scores of <strong>1.12</strong> and <strong>1.69</strong> with and without classifier-free guidance on ImageNet 256×256.
                    </p>

                    <!-- Key Points Icon Container -->
                    <div class="icon-container">
                        <div class="icon-item">
                            <img src="./static/img/icons/speed.svg" alt="Speed Icon">
                            <div><strong>17× Faster Training</strong>: REPA-E significantly accelerates diffusion training compared to REPA and 45× faster than vanilla training.</div>
                        </div>
                        <div class="icon-item">
                            <img src="./static/img/icons/quality.svg" alt="Quality Icon">
                            <div><strong>SOTA Generation Quality</strong>: Achieves FID 1.12 (w/ CFG) and 1.69 (w/o CFG) on ImageNet 256×256.</div>
                        </div>
                        <div class="icon-item">
                            <img src="./static/img/icons/dropin.svg" alt="Drop-in Icon">
                            <div><strong>Drop-in VAE Replacements</strong>: E2E-VAE serves as a superior drop-in replacement across diverse diffusion architectures.</div>
                        </div>
                    </div>

                    <div class="button-container">
                        <a href="https://arxiv.org/abs/2504.10483" class="button paper-link" target="_blank">
                            <span class="icon is-small">
                                <i class="ai ai-arxiv"></i>
                            </span>
                            arXiv
                        </a>
                        <a href="https://github.com/End2End-Diffusion/REPA-E" class="button" target="_blank">
                            <span class="icon is-small">
                                <i class="fab fa-github"></i>
                            </span>
                            <span>Code</span>
                        </a>
                        <a href="https://huggingface.co/REPA-E" class="button" target="_blank">
                            <span class="icon is-small">
                                <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face logo" style="height: 1em;">
                            </span>
                            <span>Models</span>
                        </a>
                    </div>
                </div>
                <div class="header-image">
                    <img draggable="false" data-zoomable="" src="assets/viz-results-v4.webp" alt="REPA-E Results Visualization" class="teaser-image">
                </div>
            </div>
        </div>

    <d-article>
        <div class="byline">
            <div class="byline-container">
                <p>
                    <a href="https://scholar.google.com.au/citations?user=GQzvqS4AAAAJ" class="author-link" target="_blank">Xingjian Leng<sup>1*</sup></a> &emsp;
                    <a href="https://1jsingh.github.io/" class="author-link" target="_blank">Jaskirat Singh<sup>1*</sup></a> &emsp;
                    <a href="https://hou-yz.github.io/" class="author-link" target="_blank">Yunzhong Hou<sup>1</sup></a> &emsp;
                    <br>
                    <a href="https://people.csiro.au/X/Z/Zhenchang-Xing/" class="author-link" target="_blank">Zhenchang Xing<sup>2</sup></a> &emsp;
                    <a href="https://www.sainingxie.com/" class="author-link" target="_blank">Saining Xie<sup>3</sup></a> &emsp;
                    <a href="https://zheng-lab-anu.github.io/" class="author-link" target="_blank">Liang Zheng<sup>1</sup></a>
                </p>
                <p style="text-align: center;">
                    <span class="affiliation-link"><sup>1</sup>ANU</span> &emsp;
                    <span class="affiliation-link"><sup>2</sup>Data61-CSIRO</span> &emsp;
                    <span class="affiliation-link"><sup>3</sup>New York University</span>
                </p>
                <p style="text-align: center; margin-bottom: 0;">
                    <span class="author-note"><sup>*</sup>Equal Contribution</span>
                </p>
            </div>
        </div>

        <!-- Key Findings -->
        <div class="key-findings">
            <h4 class="key-findings-title">Key Findings</h4>
            <div class="key-finding">
                <span class="key-finding-number">1</span>
                <p class="key-finding-text"><strong>End-to-end training dramatically accelerates convergence.</strong> REPA-E achieves 17× speedup over REPA and 45× over vanilla training while achieving superior generation quality.</p>
            </div>
            <div class="key-finding">
                <span class="key-finding-number">2</span>
                <p class="key-finding-text"><strong>Joint training adaptively improves VAE latent structure.</strong> The VAE learns to produce latents better suited for the diffusion model's denoising task.</p>
            </div>
            <div class="key-finding">
                <span class="key-finding-number">3</span>
                <p class="key-finding-text"><strong>E2E-VAE serves as superior drop-in replacement.</strong> Achieving SOTA FID of 1.12 (w/ CFG) and 1.69 (w/o CFG) on ImageNet 256×256.</p>
            </div>
        </div>

        <!-- News Section -->
        <div id="news" class="news-section">
            <h2 class="text">News</h2>
            <div class="news-item">
                <span class="material-icons">event</span> [Oct 2025] Released <a href="https://end2end-diffusion.github.io/repa-e-t2i/">REPA-E for T2I</a> — a family of End-to-End Tuned VAEs:
                <ul style="margin-top: 8px; margin-bottom: 4px;">
                    <li><b>Family of end-to-end tuned VAEs</b>:
                        <ul style="margin-top: 4px; margin-bottom: 4px;">
                            <li>T2I VAEs: <a href="https://huggingface.co/REPA-E/e2e-flux-vae">FLUX-VAE</a>, <a href="https://huggingface.co/REPA-E/e2e-sd3.5-vae">SD-3.5-VAE</a>, <a href="https://huggingface.co/REPA-E/e2e-qwenimage-vae">Qwen-Image-VAE</a></li>
                            <li>ImageNet VAEs: <a href="https://huggingface.co/REPA-E/e2e-sdvae-hf">SD-VAE</a>, <a href="https://huggingface.co/REPA-E/e2e-invae-hf">IN-VAE</a>, <a href="https://huggingface.co/REPA-E/e2e-vavae-hf">VA-VAE</a></li>
                        </ul>
                    </li>
                    <li><b>SOTA results on ImageNet 256×256</b>: FID <b>1.12</b> with CFG and <b>1.69</b> without CFG</li>
                    <li>All models available as <b>Hugging Face-compatible AutoencoderKL</b> checkpoints</li>
                </ul>
            </div>
            <div class="news-item">
                <span class="material-icons">event</span> [Jun 2025] REPA-E accepted at <b>ICCV 2025</b>!
            </div>
            <div class="news-item">
                <span class="material-icons">event</span> [Apr 2025] Paper, code, and pretrained models available on <a href="https://github.com/End2End-Diffusion/REPA-E">GitHub</a> and <a href="https://huggingface.co/REPA-E">Hugging Face</a>.
            </div>
        </div>

        <hr>

        <!-- Quickstart Section -->
        <div id="quickstart" class="quickstart-block">
            <h1 class="text">Quickstart</h1>

            <div class="quickstart-box">
            <!-- Tab Buttons -->
            <div class="tab-container">
                <button class="tab-button active" onclick="switchTab('tab-flux')">E2E-FLUX-VAE</button>
                <button class="tab-button" onclick="switchTab('tab-sd35')">E2E-SD3.5-VAE</button>
                <button class="tab-button" onclick="switchTab('tab-qwen')">E2E-Qwen-Image-VAE</button>
                <button class="tab-button" onclick="switchTab('tab-sdvae')">E2E-SD-VAE</button>
                <button class="tab-button" onclick="switchTab('tab-vavae')">E2E-VA-VAE</button>
                <button class="tab-button" onclick="switchTab('tab-invae')">E2E-INVAE</button>
            </div>

            <!-- FLUX-VAE Tab -->
            <div id="tab-flux" class="tab-content active">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.33.0 torch>=2.3.1</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-flux-vae").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images:</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKL
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-flux-vae").to(device)

with torch.no_grad():
    latents = vae.encode(image).latent_dist.sample()
    reconstructed = vae.decode(latents).sample</code></pre>
                </div>
            </div>

            <!-- SD3.5-VAE Tab -->
            <div id="tab-sd35" class="tab-content">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.33.0 torch>=2.3.1</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-sd3.5-vae").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images:</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKL
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-sd3.5-vae").to(device)

with torch.no_grad():
    latents = vae.encode(image).latent_dist.sample()
    reconstructed = vae.decode(latents).sample</code></pre>
                </div>
            </div>

            <!-- Qwen-Image-VAE Tab -->
            <div id="tab-qwen" class="tab-content">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.35.0 torch>=2.5.0</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKLQwenImage

vae = AutoencoderKLQwenImage.from_pretrained("REPA-E/e2e-qwenimage-vae").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images (note the frame dimension handling):</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKLQwenImage
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKLQwenImage.from_pretrained("REPA-E/e2e-qwenimage-vae").to(device)

# Add frame dimension (required for QwenImage VAE)
image_ = image.unsqueeze(2)

with torch.no_grad():
    latents = vae.encode(image_).latent_dist.sample()
    reconstructed = vae.decode(latents).sample

# Remove frame dimension
latents = latents.squeeze(2)
reconstructed = reconstructed.squeeze(2)</code></pre>
                </div>
            </div>

            <!-- SD-VAE Tab -->
            <div id="tab-sdvae" class="tab-content">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.33.0 torch>=2.3.1</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-sdvae-hf").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images (512×512 resolution):</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKL
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content)).resize((512, 512))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-sdvae-hf").to(device)

with torch.no_grad():
    latents = vae.encode(image).latent_dist.sample()
    reconstructed = vae.decode(latents).sample</code></pre>
                </div>
            </div>

            <!-- VA-VAE Tab -->
            <div id="tab-vavae" class="tab-content">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.33.0 torch>=2.3.1</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-vavae-hf").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images (512×512 resolution):</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKL
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content)).resize((512, 512))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-vavae-hf").to(device)

with torch.no_grad():
    latents = vae.encode(image).latent_dist.sample()
    reconstructed = vae.decode(latents).sample</code></pre>
                </div>
            </div>

            <!-- InVAE Tab -->
            <div id="tab-invae" class="tab-content">
                <div class="install-note">
                    <strong>Installation:</strong> <code>pip install diffusers>=0.33.0 torch>=2.3.1</code>
                </div>
                <div class="quickstart-example">
                    <h3>Quick Start</h3>
                    <p>Loading the VAE is as easy as:</p>
                    <pre><code class="language-python">from diffusers import AutoencoderKL

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-invae-hf").to("cuda")</code></pre>
                </div>
                <div class="quickstart-example">
                    <h3>Complete Example</h3>
                    <p>Full workflow for encoding and decoding images (512×512 resolution):</p>
                    <pre><code class="language-python">from io import BytesIO
import requests
from diffusers import AutoencoderKL
import numpy as np
import torch
from PIL import Image

response = requests.get("https://raw.githubusercontent.com/End2End-Diffusion/fuse-dit/main/assets/example.png")
device = "cuda"

image = torch.from_numpy(
    np.array(
        Image.open(BytesIO(response.content)).resize((512, 512))
    )
).permute(2, 0, 1).unsqueeze(0).to(torch.float32) / 127.5 - 1
image = image.to(device)

vae = AutoencoderKL.from_pretrained("REPA-E/e2e-invae-hf").to(device)

with torch.no_grad():
    latents = vae.encode(image).latent_dist.sample()
    reconstructed = vae.decode(latents).sample</code></pre>
                </div>
            </div>
            </div>

            <p class="text" style="margin-top: 0px;">For complete usage examples and integration with diffusion models, see the individual <a href="https://huggingface.co/REPA-E">model cards on Hugging Face</a>.</p>
        </div>

        <hr>

        <!-- Overview Section -->
        <div id="overview" class="overview-block">
            <h1 class="text">Overview</h1>

            <div class="sidenote-container">
                <p class="text">
                    We address a fundamental question: <strong><em>Can latent diffusion models and their VAE tokenizer be trained end-to-end?</em></strong> While training both components jointly with standard diffusion loss is observed to be ineffective — often degrading final performance — we show that this limitation can be overcome using a simple representation-alignment (REPA) loss. Our proposed method, <strong>REPA-E</strong>, enables stable and effective joint training of both the VAE and the diffusion model, achieving state-of-the-art FID scores of <strong>1.12</strong> and <strong>1.69</strong> with and without classifier-free guidance on ImageNet 256×256.
                </p>
                <aside class="sidenote">Previous attempts at end-to-end training often led to training instability or degraded reconstruction quality. REPA loss provides the crucial guidance signal.</aside>
            </div>

            <d-figure id="fig-overview">
                <figure>
                    <img data-zoomable="" draggable="false" src="assets/a-overview-v4.webp" alt="REPA-E Overview">
                    <figcaption>
                        <strong>REPA-E Overview.</strong> End-to-end training of VAE and diffusion model using representation alignment loss.
                    </figcaption>
                </figure>
            </d-figure>

            <p class="text">
                Through extensive evaluations, we demonstrate that our end-to-end training approach <strong>REPA-E</strong> offers four key advantages:
            </p>

            <ol class="text">
                <li><strong><a href="#accelerated-performance">E2E Leads to Faster Training</a></strong>: REPA-E significantly speeds up diffusion training by over 17× and 45× compared to REPA and vanilla training recipes, respectively.</li>
                <li><strong><a href="#improved-latent-space">E2E Leads to Improved Latent Space</a></strong>: Joint tuning adaptively enhances latent space structure across different VAE architectures.</li>
                <li><strong><a href="#drop-in-replacements">E2E VAEs are Better than Regular VAEs</a></strong>: The resulting E2E-VAE serves as a drop-in replacement, improving convergence and generation quality across diverse LDM architectures. REPA-E also enables joint training of both VAE and LDM from scratch.</li>
            </ol>

            <div class="finding-box">
                <ul>
                    <li><strong>Core Insight:</strong> End-to-end training of VAE and diffusion model becomes effective with REPA loss, overcoming previous instability issues and achieving SOTA generation quality.</li>
                </ul>
            </div>
        </div>

        <hr>

        <!-- Accelerated Performance Section -->
        <div id="accelerated-performance" class="results-block">
            <h1 class="text">1. E2E Leads to Faster Training</h1>

            <div class="sidenote-container">
                <p class="text">
                    REPA-E dramatically accelerates diffusion model training while achieving superior generation quality. We demonstrate consistent improvements across different model scales and VAE architectures.
                </p>
                <aside class="sidenote">The key insight is that end-to-end VAE tuning allows the latent space to adapt to the diffusion model's needs, reducing the optimization burden.</aside>
            </div>

            <ul class="text">
                <li><strong>Better performance with fewer epochs:</strong> REPA-E achieves gFID of <strong>4.07</strong> in just 80 epochs, significantly outperforming MaskDiT (<strong>5.69</strong> with 1600 epochs) and FasterDiT (<strong>7.91</strong> with 400 epochs)</li>
                <li><strong>Robust across architectures:</strong> Performance improvements remain consistent across different model scales (SiT-B/L/XL) and VAE architectures (SD-VAE, IN-VAE, VA-VAE)</li>
                <li><strong>Enhanced image quality across training:</strong> Using identical noise and labels, REPA-E generates structurally superior images compared to REPA baseline at 50K, 100K, and 400K training iterations</li>
            </ul>

            <!-- Table 1: Main Comparison -->
            <div class="table-container" style="margin: 30px auto; max-width: 700px;">
                <table class="data-table" style="width: 100%; font-size: 0.9em;">
                    <caption style="margin-bottom: 10px;">Comparison of methods with and without end-to-end tuning</caption>
                    <thead>
                        <tr>
                            <th style="text-align: left;">Method</th>
                            <th style="text-align: center;">Tokenizer</th>
                            <th style="text-align: center;">Epochs</th>
                            <th style="text-align: center;">gFID↓</th>
                            <th style="text-align: center;">sFID↓</th>
                            <th style="text-align: center;">IS↑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="highlight-gray">
                            <td colspan="6" style="text-align: center; font-weight: bold;">Without End-to-End Tuning</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">MaskDiT [54]</td>
                            <td style="text-align: center;" rowspan="4">SD-VAE</td>
                            <td style="text-align: center;">1600</td>
                            <td style="text-align: center;">5.69</td>
                            <td style="text-align: center;">10.34</td>
                            <td style="text-align: center;"><strong>177.9</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">DiT [34]</td>
                            <td style="text-align: center;">1400</td>
                            <td style="text-align: center;">9.62</td>
                            <td style="text-align: center;">6.85</td>
                            <td style="text-align: center;">121.5</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">SiT [30]</td>
                            <td style="text-align: center;">1400</td>
                            <td style="text-align: center;">8.61</td>
                            <td style="text-align: center;">6.32</td>
                            <td style="text-align: center;">131.7</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">FasterDiT [49]</td>
                            <td style="text-align: center;">400</td>
                            <td style="text-align: center;">7.91</td>
                            <td style="text-align: center;">5.45</td>
                            <td style="text-align: center;">131.3</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;" rowspan="4">REPA [52]</td>
                            <td style="text-align: center;" rowspan="4">SD-VAE</td>
                            <td style="text-align: center;">20</td>
                            <td style="text-align: center;">19.40</td>
                            <td style="text-align: center;">6.06</td>
                            <td style="text-align: center;">67.4</td>
                        </tr>
                        <tr>
                            <td style="text-align: center;">40</td>
                            <td style="text-align: center;">11.10</td>
                            <td style="text-align: center;">6.06</td>
                            <td style="text-align: center;">67.4</td>
                        </tr>
                        <tr>
                            <td style="text-align: center;">80</td>
                            <td style="text-align: center;">7.90</td>
                            <td style="text-align: center;">5.06</td>
                            <td style="text-align: center;">122.6</td>
                        </tr>
                        <tr>
                            <td style="text-align: center;">800</td>
                            <td style="text-align: center;">5.90</td>
                            <td style="text-align: center;">5.73</td>
                            <td style="text-align: center;">157.8</td>
                        </tr>
                        <tr class="highlight-gray">
                            <td colspan="6" style="text-align: center; font-weight: bold;">With End-to-End Tuning (Ours)</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;" rowspan="3"><strong>REPA-E</strong></td>
                            <td style="text-align: center;" rowspan="3">SD-VAE*</td>
                            <td style="text-align: center;">20</td>
                            <td style="text-align: center;">12.83</td>
                            <td style="text-align: center;">5.04</td>
                            <td style="text-align: center;">88.8</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: center;">40</td>
                            <td style="text-align: center;">7.17</td>
                            <td style="text-align: center;"><strong>4.39</strong></td>
                            <td style="text-align: center;">123.7</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: center;">80</td>
                            <td style="text-align: center;"><strong>4.07</strong></td>
                            <td style="text-align: center;">4.60</td>
                            <td style="text-align: center;"><u>161.8</u></td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Table 2: Diff. Model Comparison -->
            <div class="table-container" style="margin: 30px auto; max-width: 700px;">
                <table class="data-table" style="width: 100%; font-size: 0.9em;">
                    <caption style="margin-bottom: 10px;">Scalability across diffusion model sizes</caption>
                    <thead>
                        <tr>
                            <th style="text-align: left;">Diff. Model</th>
                            <th style="text-align: center;">gFID↓</th>
                            <th style="text-align: center;">sFID↓</th>
                            <th style="text-align: center;">IS↑</th>
                            <th style="text-align: center;">Prec.↑</th>
                            <th style="text-align: center;">Rec.↑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style="text-align: left;">SiT-B (130M)</td>
                            <td style="text-align: center;">49.5</td>
                            <td style="text-align: center;">7.00</td>
                            <td style="text-align: center;">27.5</td>
                            <td style="text-align: center;">0.46</td>
                            <td style="text-align: center;"><strong>0.59</strong></td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>34.8</strong></td>
                            <td style="text-align: center;"><strong>6.31</strong></td>
                            <td style="text-align: center;"><strong>39.1</strong></td>
                            <td style="text-align: center;"><strong>0.57</strong></td>
                            <td style="text-align: center;"><strong>0.59</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">SiT-L (458M)</td>
                            <td style="text-align: center;">24.1</td>
                            <td style="text-align: center;">6.25</td>
                            <td style="text-align: center;">55.7</td>
                            <td style="text-align: center;">0.62</td>
                            <td style="text-align: center;"><strong>0.60</strong></td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>16.3</strong></td>
                            <td style="text-align: center;"><strong>5.69</strong></td>
                            <td style="text-align: center;"><strong>75.0</strong></td>
                            <td style="text-align: center;"><strong>0.68</strong></td>
                            <td style="text-align: center;"><strong>0.60</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">SiT-XL (675M)</td>
                            <td style="text-align: center;">19.4</td>
                            <td style="text-align: center;">6.06</td>
                            <td style="text-align: center;">67.4</td>
                            <td style="text-align: center;">0.64</td>
                            <td style="text-align: center;">0.61</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>12.8</strong></td>
                            <td style="text-align: center;"><strong>5.04</strong></td>
                            <td style="text-align: center;"><strong>88.8</strong></td>
                            <td style="text-align: center;"><strong>0.71</strong></td>
                            <td style="text-align: center;">0.58</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Table 3: Autoencoder Comparison -->
            <div class="table-container" style="margin: 30px auto; max-width: 700px;">
                <table class="data-table" style="width: 100%; font-size: 0.9em;">
                    <caption style="margin-bottom: 10px;">Generalization across different VAE architectures</caption>
                    <thead>
                        <tr>
                            <th style="text-align: left;">Autoencoder</th>
                            <th style="text-align: center;">gFID↓</th>
                            <th style="text-align: center;">sFID↓</th>
                            <th style="text-align: center;">IS↑</th>
                            <th style="text-align: center;">Prec.↑</th>
                            <th style="text-align: center;">Rec.↑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style="text-align: left;">SD-VAE [39]</td>
                            <td style="text-align: center;">24.1</td>
                            <td style="text-align: center;">6.25</td>
                            <td style="text-align: center;">55.7</td>
                            <td style="text-align: center;">0.62</td>
                            <td style="text-align: center;"><strong>0.60</strong></td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>16.3</strong></td>
                            <td style="text-align: center;"><strong>5.69</strong></td>
                            <td style="text-align: center;"><strong>75.0</strong></td>
                            <td style="text-align: center;"><strong>0.68</strong></td>
                            <td style="text-align: center;"><strong>0.60</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">IN-VAE (<em>f16d32</em>)</td>
                            <td style="text-align: center;">22.7</td>
                            <td style="text-align: center;"><strong>5.47</strong></td>
                            <td style="text-align: center;">56.0</td>
                            <td style="text-align: center;">0.62</td>
                            <td style="text-align: center;"><strong>0.62</strong></td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>12.7</strong></td>
                            <td style="text-align: center;">5.57</td>
                            <td style="text-align: center;"><strong>84.0</strong></td>
                            <td style="text-align: center;"><strong>0.69</strong></td>
                            <td style="text-align: center;"><strong>0.62</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">VA-VAE [48]</td>
                            <td style="text-align: center;">12.8</td>
                            <td style="text-align: center;">6.47</td>
                            <td style="text-align: center;">83.8</td>
                            <td style="text-align: center;">0.71</td>
                            <td style="text-align: center;">0.58</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>+REPA-E (Ours)</strong></td>
                            <td style="text-align: center;"><strong>11.1</strong></td>
                            <td style="text-align: center;"><strong>5.31</strong></td>
                            <td style="text-align: center;"><strong>88.8</strong></td>
                            <td style="text-align: center;"><strong>0.72</strong></td>
                            <td style="text-align: center;">0.61</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <d-figure id="fig-scaling">
                <figure style="max-width: 80%; margin: 0 auto;">
                    <img data-zoomable="" draggable="false" src="assets/visual-scaling-v4.webp" alt="Visual comparison at different iterations">
                    <figcaption>
                        <strong>Qualitative comparison between REPA and REPA-E.</strong> Images generated at different training iterations using identical noise and labels.
                    </figcaption>
                </figure>
            </d-figure>

            <div class="finding-box">
                <ul>
                    <li><strong>Finding 1:</strong> REPA-E achieves 17× speedup over REPA and 45× over vanilla training while delivering superior generation quality across all tested configurations.</li>
                </ul>
            </div>
        </div>

        <hr>

        <!-- Improved Latent Space Section -->
        <div id="improved-latent-space" class="results-block">
            <h1 class="text">2. E2E Leads to Improved Latent Space</h1>

            <div class="sidenote-container">
                <p class="text">
                    End-to-end training with REPA-E adaptively refines the VAE's latent space structure without explicit regularization. Different VAE architectures exhibit different failure modes, and REPA-E addresses each appropriately.
                </p>
                <aside class="sidenote">Different VAEs have different failure modes—SD-VAE tends toward high-frequency artifacts while IN-VAE/VA-VAE over-smooth. REPA-E addresses each appropriately.</aside>
            </div>

            <ul class="text">
                <li><strong>Adaptive refinement without explicit regularization:</strong> REPA-E automatically adapts to each VAE's unique latent space characteristics</li>
                <li><strong>PCA visualization:</strong> Using principal component analysis, we project VAE latents to RGB channels, revealing how end-to-end tuning improves latent representation quality</li>
                <li><strong>Architecture-specific benefits:</strong>
                    <ul>
                        <li><strong>SD-VAE enhancement:</strong> Reduces high-frequency noise components for smoother latent representations</li>
                        <li><strong>IN-VAE & VA-VAE enhancement:</strong> Adds essential structural details to over-smoothed latent representations</li>
                    </ul>
                </li>
            </ul>

            <d-figure id="fig-pca">
                <figure style="max-width: 80%; margin: 0 auto;">
                    <img data-zoomable="" draggable="false" src="assets/pca-analysis-v11.webp" alt="PCA Analysis of Latent Space">
                    <figcaption>
                        <strong>PCA visualization of VAE latent spaces.</strong> End-to-end tuning with REPA-E improves latent representation quality across different VAE architectures.
                    </figcaption>
                </figure>
            </d-figure>

            <div class="finding-box">
                <ul>
                    <li><strong>Finding 2:</strong> End-to-end training adaptively improves latent space structure—reducing noise in SD-VAE while adding structural detail to IN-VAE/VA-VAE—without explicit regularization.</li>
                </ul>
            </div>
        </div>

        <hr>

        <!-- Drop-in Replacements Section -->
        <div id="drop-in-replacements" class="results-block">
            <h1 class="text">3. E2E VAEs are Better than Regular VAEs</h1>

            <div class="sidenote-container">
                <p class="text">
                    The end-to-end tuned E2E-VAE serves as a universal drop-in replacement for standard VAEs, delivering consistent improvements across diverse diffusion model architectures without requiring any modifications to the training pipeline.
                </p>
                <aside class="sidenote">E2E-VAE can be directly loaded using the standard diffusers API—no custom wrappers or code changes required.</aside>
            </div>

            <ul class="text">
                <li><strong>Universal improvement:</strong> E2E-VAE serves as a drop-in replacement for original VAEs, delivering superior performance across diverse diffusion architectures</li>
                <li><strong>State-of-the-art generation quality:</strong> Achieves gFID of <strong>1.12</strong> (w/ CFG) and <strong>1.69</strong> (w/o CFG) when training with REPA for 800 epochs</li>
                <li><strong>Comprehensive performance superiority:</strong> Achieves gFID of <strong>3.46</strong> with SiT-XL and REPA (vs. <strong>4.88</strong> with VA-VAE and <strong>7.90</strong> with SD-VAE)</li>
                <li><strong>Architecture-robust performance:</strong> E2E-VAE maintains strong generation quality across diffusion models with and without REPA</li>
            </ul>

            <d-figure id="fig-dropin">
                <figure>
                    <img data-zoomable="" draggable="false" src="assets/e2e-vae-eval.webp" alt="Drop-in VAE Performance Comparison">
                    <figcaption>
                        <strong>E2E-VAE as drop-in replacement.</strong> Comparison showing E2E-VAE delivers consistent improvements across different diffusion architectures.
                    </figcaption>
                </figure>
            </d-figure>

            <!-- From-Scratch Training Subsection -->
            <h3 class="text" id="from-scratch">From-Scratch Training</h3>

            <p class="text">
                REPA-E enables effective joint training of both VAE and LDM from scratch, eliminating the need for separate VAE pre-training while still achieving superior performance compared to traditional approaches.
            </p>

            <ul class="text">
                <li><strong>End-to-end training from scratch:</strong> REPA-E can jointly train both VAE and LDM from scratch in an end-to-end manner, without requiring VAE pre-training</li>
                <li><strong>Strong performance even without initialization:</strong> While initializing the VAE with pretrained weights helps slightly improve results, from-scratch training still achieves gFID of <strong>4.34</strong> at 80 epochs, significantly outperforming REPA (<strong>7.90</strong>)</li>
            </ul>

            <!-- From-Scratch Training Table -->
            <div style="margin: 30px auto; max-width: 600px;">
                <table class="data-table" style="width: 100%; font-size: 0.9em;">
                    <caption style="margin-bottom: 10px;">From-scratch training results. REPA-E enables effective joint training without VAE pre-training.</caption>
                    <thead>
                        <tr>
                            <th style="text-align: left;">Method</th>
                            <th style="text-align: center;">gFID↓</th>
                            <th style="text-align: center;">sFID↓</th>
                            <th style="text-align: center;">IS↑</th>
                            <th style="text-align: center;">Prec.↑</th>
                            <th style="text-align: center;">Rec.↑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="highlight-gray">
                            <td colspan="6" style="text-align: center; font-weight: bold;">100K Iterations (20 Epochs)</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA [52]</td>
                            <td style="text-align: center;">19.40</td>
                            <td style="text-align: center;">6.06</td>
                            <td style="text-align: center;">67.4</td>
                            <td style="text-align: center;">0.64</td>
                            <td style="text-align: center;"><strong>0.61</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA-E (scratch)</td>
                            <td style="text-align: center;">14.12</td>
                            <td style="text-align: center;">7.87</td>
                            <td style="text-align: center;">83.5</td>
                            <td style="text-align: center;">0.70</td>
                            <td style="text-align: center;">0.59</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>REPA-E (VAE init.)</strong></td>
                            <td style="text-align: center;"><strong>12.83</strong></td>
                            <td style="text-align: center;"><strong>5.04</strong></td>
                            <td style="text-align: center;"><strong>88.8</strong></td>
                            <td style="text-align: center;"><strong>0.71</strong></td>
                            <td style="text-align: center;">0.58</td>
                        </tr>
                        <tr class="highlight-gray">
                            <td colspan="6" style="text-align: center; font-weight: bold;">200K Iterations (40 Epochs)</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA [52]</td>
                            <td style="text-align: center;">11.10</td>
                            <td style="text-align: center;">5.05</td>
                            <td style="text-align: center;">100.4</td>
                            <td style="text-align: center;">0.69</td>
                            <td style="text-align: center;"><strong>0.64</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA-E (scratch)</td>
                            <td style="text-align: center;">7.54</td>
                            <td style="text-align: center;">6.17</td>
                            <td style="text-align: center;">120.4</td>
                            <td style="text-align: center;"><strong>0.74</strong></td>
                            <td style="text-align: center;">0.61</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>REPA-E (VAE init.)</strong></td>
                            <td style="text-align: center;"><strong>7.17</strong></td>
                            <td style="text-align: center;"><strong>4.39</strong></td>
                            <td style="text-align: center;"><strong>123.7</strong></td>
                            <td style="text-align: center;"><strong>0.74</strong></td>
                            <td style="text-align: center;">0.62</td>
                        </tr>
                        <tr class="highlight-gray">
                            <td colspan="6" style="text-align: center; font-weight: bold;">400K Iterations (80 Epochs)</td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA [52]</td>
                            <td style="text-align: center;">7.90</td>
                            <td style="text-align: center;">5.06</td>
                            <td style="text-align: center;">122.6</td>
                            <td style="text-align: center;">0.70</td>
                            <td style="text-align: center;"><strong>0.65</strong></td>
                        </tr>
                        <tr>
                            <td style="text-align: left;">REPA-E (scratch)</td>
                            <td style="text-align: center;">4.34</td>
                            <td style="text-align: center;">4.44</td>
                            <td style="text-align: center;">154.3</td>
                            <td style="text-align: center;">0.75</td>
                            <td style="text-align: center;">0.63</td>
                        </tr>
                        <tr style="background-color: #e6ffe6;">
                            <td style="text-align: left;"><strong>REPA-E (VAE init.)</strong></td>
                            <td style="text-align: center;"><strong>4.07</strong></td>
                            <td style="text-align: center;">4.60</td>
                            <td style="text-align: center;"><strong>161.8</strong></td>
                            <td style="text-align: center;"><strong>0.76</strong></td>
                            <td style="text-align: center;">0.62</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="finding-box">
                <ul>
                    <li><strong>Finding 3:</strong> E2E-VAE serves as a universal drop-in replacement, achieving SOTA FID of 1.12 (w/ CFG) and 1.69 (w/o CFG) across diverse diffusion architectures.</li>
                </ul>
            </div>
        </div>

        <hr>

        <!-- Conclusion Section -->
        <div id="conclusion" class="conclusion-block">
            <h1 class="text">Conclusion</h1>

            <p class="text">
                We introduced <strong>REPA-E</strong>, a method for end-to-end training of latent diffusion models and their VAE tokenizers. Our key findings demonstrate that:
            </p>

            <ol class="text">
                <li>End-to-end training with REPA loss achieves <strong>17× speedup</strong> over REPA and <strong>45× speedup</strong> over vanilla training</li>
                <li>Joint training adaptively improves VAE latent space structure across different architectures</li>
                <li>E2E-VAE serves as a superior drop-in replacement, achieving <strong>SOTA FID of 1.12</strong> on ImageNet 256×256</li>
            </ol>

            <p class="text">
                These results establish end-to-end training as a practical and effective approach for training latent diffusion models, opening new possibilities for joint architecture optimization and task-specific adaptations.
            </p>
        </div>

    </d-article>

    <d-appendix>
        <h3>BibTeX</h3>
        <div class="bibtex-container" style="position: relative;">
            <button class="copy-btn" id="copy-bibtex-btn" onclick="copyBibtex()" style="position: absolute; top: 8px; right: 8px; background: #2563eb; color: white; border: none; padding: 6px 12px; border-radius: 4px; cursor: pointer; font-size: 0.85em;">
                Copy
            </button>
            <pre class="bibtex" id="bibtex-content" style="background: #f5f5f5; padding: 15px; border-radius: 5px; font-family: 'Courier New', monospace; font-size: 0.9em; line-height: 1.6; overflow-x: auto;">@article{leng2025repae,
  title={REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers},
  author={Xingjian Leng and Jaskirat Singh and Yunzhong Hou and Zhenchang Xing and Saining Xie and Liang Zheng},
  year={2025},
  journal={arXiv preprint arXiv:2504.10483},
}</pre>
        </div>

        <h3>References</h3>
        <div style="font-size: 0.9em; line-height: 1.6; color: #444;">
            <p style="padding-left: 24px; text-indent: -24px;">
                [1] Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2022). High-resolution image synthesis with latent diffusion models. <em>CVPR</em>.
            </p>
            <p style="padding-left: 24px; text-indent: -24px;">
                [2] Peebles, W., & Xie, S. (2023). Scalable diffusion models with transformers. <em>ICCV</em>.
            </p>
            <p style="padding-left: 24px; text-indent: -24px;">
                [3] Yu, S., Sohn, K., Kim, S., & Shin, J. (2024). Representation alignment for generation: Training diffusion transformers is easier than you think. <em>arXiv preprint arXiv:2410.06940</em>.
            </p>
            <p style="padding-left: 24px; text-indent: -24px;">
                [4] Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., & Fei-Fei, L. (2009). ImageNet: A large-scale hierarchical image database. <em>CVPR</em>.
            </p>
            <p style="padding-left: 24px; text-indent: -24px;">
                [5] Esser, P., Kulal, S., Blattmann, A., et al. (2024). Scaling rectified flow transformers for high-resolution image synthesis. <em>ICML</em>.
            </p>
        </div>

        <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; font-size: 12px; color: #888; text-align: center;">
            <p>We thank the <a href="https://github.com/sihyun-yu/REPA/tree/gh-pages" target="_blank">REPA project</a> for inspiration. Last updated: October 2025.</p>
        </footer>
    </d-appendix>

<!-- BibTeX copy function -->
<script>
function copyBibtex() {
    const bibtexContent = document.getElementById('bibtex-content').innerText;
    const btn = document.getElementById('copy-bibtex-btn');

    if (navigator.clipboard && navigator.clipboard.writeText) {
        navigator.clipboard.writeText(bibtexContent).then(function() {
            btn.innerText = 'Copied!';
            setTimeout(function() {
                btn.innerText = 'Copy';
            }, 2000);
        }).catch(function(err) {
            fallbackCopy(bibtexContent, btn);
        });
    } else {
        fallbackCopy(bibtexContent, btn);
    }
}

function fallbackCopy(text, btn) {
    const textarea = document.createElement('textarea');
    textarea.value = text;
    textarea.style.position = 'fixed';
    textarea.style.opacity = '0';
    document.body.appendChild(textarea);
    textarea.select();
    try {
        document.execCommand('copy');
        btn.innerText = 'Copied!';
        setTimeout(function() {
            btn.innerText = 'Copy';
        }, 2000);
    } catch (err) {
        btn.innerText = 'Failed';
        setTimeout(function() {
            btn.innerText = 'Copy';
        }, 2000);
    }
    document.body.removeChild(textarea);
}
</script>

<!-- TOC scroll highlighting -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    const tocContainer = document.querySelector('.toc-container');
    const tocLinks = document.querySelectorAll('.toc-container a');
    const sections = ['quickstart', 'overview', 'accelerated-performance', 'improved-latent-space', 'drop-in-replacements', 'conclusion'];

    function updateTOC() {
        const scrollPos = window.scrollY;
        const header = document.getElementById('header-container');
        const headerBottom = header ? header.offsetTop + header.offsetHeight : 0;

        // Show/hide TOC based on scroll position
        if (scrollPos > headerBottom - 100) {
            tocContainer.classList.add('visible');
        } else {
            tocContainer.classList.remove('visible');
        }

        // Update active link
        let current = '';
        const scrollPosForActive = scrollPos + 150;

        sections.forEach(id => {
            const section = document.getElementById(id);
            if (section && scrollPosForActive >= section.offsetTop) {
                current = id;
            }
        });

        tocLinks.forEach(link => {
            link.classList.remove('active');
            if (link.getAttribute('href') === '#' + current) {
                link.classList.add('active');
            }
        });
    }

    window.addEventListener('scroll', updateTOC);
    updateTOC();
});
</script>

</body>
</html>
